{
    "Autor": "Filipe Jerônimo Pereira",
    "Título": "AVALIAÇÃO DA PLATAFORMA OPEN MPI PARA PARALELIZAÇÃO DO PROCESSO DE COMPILAÇÃO DE SOFTWARE",
    "Ano de publicação": 2014,
    "Local de publicação": "Araranguá",
    "Orientador(a)": "Prof. Dr. Anderson Luiz Fernandes Perez",
    "Coorientador(a)": null,
    "Resumo": "Os programas de computador estão cada vez maiores e mais complexos, exigindo maior capacidade de processamento do hardware. Uma alternativa para melhorar o tempo de execução de programas é o uso de sistemas multiprocessados com destaque à computação paralela. Em processos de desenvolvimento de software que usam o modelo em cascata o tempo de compilação pode se tornar um problema em projetos grandes, sobretudo ao atendimento dos prazos para a entrega do produto final, em virtude das várias etapas envolvidas neste processo. O uso de um ambiente de programação paralela pode tornar o tempo de compilação menor, uma vez que o processo de compilação será divididos em várias tarefas que serão executadas em processadores distintos. Neste trabalho são descritos os resultados obtidos na paralelização do processo de compilação de software utilizando a plataforma Open MPI que é uma implementação Open Source do padrão MPI (Message Passing Interface) e que fornece uma camada de abstração capaz de criar um ambiente computacional distribuído. Os resultados obtidos a partir da compilação de um sistema de teste na plataforma Open MPI são comparados com os resultados obtidos a partir da compilação do mesmo sistema em ambiente monoprocessado.",
    "Palavras-chave": "Open MPI, computação paralela, compilação.",
    "Introdução": "A crescente demanda por processos gerenciados por programas de computador faz com que as suas funcionalidades cresçam exponencialmente. Desse modo os programas se tornam cada vez maiores e complexos, exigindo maior capacidade de processamento e manipulação da informação. Pereira (2006) destaca que o modo de produção de software passou de artesanal para um modo de produção racional, visando atender essa crescente demanda de softwares com maior qualidade e também à necessidade de se produzir em um curto intervalo de tempo. Segundo as estatísticas da Scientific American, projetos de software ultrapassam em 50% o tempo estipulado no cronograma para a sua conclusão (HAZAN, 2004). O Standish Group (2013) possui levantamento estatístico sobre projetos de software baseado em uma base de dados com quase 50.000 projetos que provê uma visão global, tendo a maior concentração nos Estados Unidos e Europa, onde 60% dos projetos são dos Estados Unidos, 25% são da Europa e os 15% restantes são dos demais países. A pesquisa revela que 39% dos projetos são finalizados dentro do prazo e custos conforme previsto, 43% dos projetos são concluídos com atraso, orçamento superior e/ou menos recursos e funcionalidades do que o previsto, e 18% são cancelados. Na construção de um programa, os algoritmos escritos em linguagens de programação como C, Java, Python, entre outras, necessitam de um processo de tradução da linguagem compreendida pelo homem, dita linguagem de alto nível, para a linguagem de máquina, a esse processo se dá o nome de compilação. Em um projeto de desenvolvimento de software o processo de compilação pode representar um problema para cumprir o prazo, pois se o modelo utilizado no projeto for do tipo cascata então a etapa de teste precisa aguardar que o processo de compilação seja concluído, e se esse atrasar então consequentemente todo o cronograma será prejudicado. Diante do exposto acima e da limitação física e monetária para aumentar o desempenho dos processadores, distribuir uma tarefa serializada para mais de um computador pode ser uma solução viável para reduzir o tempo de conclusão da mesma sem grandes investimentos em infraestrutura. Como a maioria das corporações dispõem de uma rede interna de computadores, uma rotina que poderia ser otimizada pela técnica de paralelismo é a compilação, pois essa tarefa aplica processamento em uma série de arquivos para produzir uma única saída, podendo-se assim dividir o trabalho em cargas menores. Mesmo que haja dependência entre os arquivos, onde a ordem deve ser respeitada, um roteiro pode ser aplicado para que a rotina seja sincronizada, sendo necessário o conhecimento sobre a estrutura do programa a ser compilado. O projeto Open MPI (Message Passing Interface) é uma implementação open source MPI-2, que é desenvolvido e mantido por um consórcio de acadêmicos, pesquisadores e parceiros da indústria. MPI é um conjunto de especificações de protocolos de comunicação de dados para computação paralela. O Open MPI é capaz de combinar o conhecimento, tecnologias e recursos de toda a comunidade de computação de alto desempenho, a fim de construir a melhor biblioteca MPI disponível, e oferece vantagens para fornecedores de sistemas e software, desenvolvedores de aplicativos e pesquisadores de ciência da computação (Open-Mpi.Org, 2014). Com o Open MPI aplicado em um ambiente multiprocessado é possível criar uma infraestrutura capaz de executar rotinas de forma paralela. Com este recurso o problema do tempo elevado de compilação de software, pode ser reduzido ao distribuir a rotina em partes menores para ser executado em mais de um processador ao mesmo tempo.",
    "Conclusão": "Neste trabalho buscou-se uma alternativa para reduzir o tempo de compilação de programas de computador. Otimizar o uso dos recursos disponíveis em um ambiente computacional é uma proposta da computação paralela e distribuída, por isso este tipo de solução foi empregada neste problema. Os resultados obtidos dentro do ambiente de teste foram satisfatórios e revelaram um potencial a ser explorado. O trabalho realizado com a plataforma Open MPI utilizou apenas os procedimentos básicos para criar um ambiente paralelo, porém há muito em relação à API que pode ser estudado. O programa de teste demonstrou-se eficiente até mesmo ao utilizar os recursos de um único computador, ao dividir a tarefa no número de núcleos físicos disponíveis. Mesmo todos os testes com a versão paralela do programa de testes tendo superado a versão serial, algumas configurações não se apresentaram interessantes por representar pouca aceleração em vista dos recursos empregados, por isso escolher a melhor configuração conforme o ambiente disponível é fundamental para obter o melhor resultado. A implementação Open MPI é utilizada em grandes clusters, como o RoadRunner da IBM, líder do top500 em 2008, uma lista que classifica os computadores mais velozes do mundo (PAULA; PRADO; CORNACCHIA, 2008). O RoadRunner alcançou em 2008 a marca histórica de 1 PFLOPS (Peta Floating-point Operations Per Second), e foi desativado em 31/03/2013 para ser substituído por um computador menor, que custou menos da metade do preço do antecessor e ainda é um pouco mais rápido (IG, 2013). Mas além da aplicação do Open MPI em grandes clusters, a API também apresentou bons resultados mesmo em computadores IBM-PC, tal como o ambiente de teste utilizado neste trabalho. Isso representa uma área bastante interessante para ser estudada e aplicada em problemas de computação de alta performance."
}