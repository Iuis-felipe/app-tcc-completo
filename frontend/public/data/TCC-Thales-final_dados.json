{
    "Autor": "Thales do Nascimento da Silva",
    "Título": "Uma arquitetura para descoberta de conhecimento a partir de bases textuais",
    "Ano de publicação": 2012,
    "Local de publicação": "Araranguá",
    "Orientador(a)": "Professor Alexandre Leopoldo Gonçalves",
    "Coorientador(a)": [
        "Dr. Anderson Luiz Fernandes Perez",
        "Dra. Luciana Bolan Frigo"
    ],
    "Resumo": "Atualmente, o volume de informação gerado aumenta exponencialmente, sendo que uma parcela significativa das informações encontra-se em formato textual. A partir desse formato é possível extrair determinados conhecimentos. Entretanto, face ao grande volume de informações disponíveis, seja na web ou mesmo nas organizações, tal tarefa constitui-se como um desafio computacional. Superados os obstáculos, o conhecimento obtido através de informações textuais pode ser utilizado na tomada de decisão com o intuito de gerar vantagem competitiva. Um dos meios de se extrair conhecimento é através da utilização do processo de Descoberta de Conhecimento em Bases de Dados e, no caso de informações textuais, através do processo de Descoberta de Conhecimento em Textos. De maneira geral, os processos de descoberta de conhecimento tradicionais são custosos quando aplicados em grandes coleções de documentos, por exemplo, a web. Com este pressuposto é proposto neste trabalho uma arquitetura para descoberta de conhecimento a partir de bases textuais almejando sua utilização em grandes fontes de informação. Para atingir este objetivo, a proposta utiliza, além da computação distribuída visando o aumento de desempenho, um modelo com base no conceito de correlação rápida. A demonstração de viabilidade é realizada através de um protótipo que implementa a arquitetura proposta. O protótipo tem a capacidade de gerar informações que relacionam padrões textuais (termos) e de permitir uma visão da evolução temporal em determinado domínio de problema. A aplicação do protótipo em um cenário possibilitou demonstrar que a arquitetura proposta é capaz de obter resultados consistentes e satisfatórios, tanto para o entendimento de determinado domínio, quanto para a análise de grandes bases textuais.",
    "Palavras-chave": [
        "Descoberta de Conhecimento",
        "Bases Textuais",
        "Correlação de Informação",
        "Computação Distribuída"
    ],
    "Introdução": "A evolução das tecnologias da informação vem promovendo diversas mudanças na sociedade em geral. Entre elas está a disponibilização de uma quantidade cada vez mais crescente de informações, resultado principalmente do aumento da capacidade de processamento e armazenamento. Este fenômeno torna-se cada vez mais evidente e vem sendo observado por diversos estudiosos da área.\nEm 2003 o mundo produzia entre um e dois exabytes de informação nova por ano, ou seja, algo em torno de 250 megabytes para cada habitante na Terra (LYMAN; VARIAN, 2003). Um exabyte equivale a pouco mais de um bilhão de gigabytes. Estima-se que documentos impressos, que eram o meio mais comum de informação textual há algumas décadas, hoje representam apenas 0,003% da informação gerada anualmente (LYMAN; VARIAN, 2003).\nO suporte ao aumento de informação é possível graças a evolução dos meios de armazenamento magnéticos. Segundo Hilbert (2011), em 2000 os meios de armazenamento magnéticos representavam 5% da capacidade mundial, saltando para 45% em 2007, e a capacidade de armazenamento per capita que era de 2.866 megabytes em 1993, passou a ser de 44.716 megabytes em 2007.\nParte considerável dessa informação encontra-se na forma de textos nos mais diversos formatos. Desde a década de noventa estudos como os de Wilks e Catizone (1999) já apontavam que 80% da informação encontrava-se na forma textual. A cada ano são produzidos aproximadamente 968 mil livros, 80 mil revistas, 40 mil periódicos, bilhões de documentos (LYMAN; VARIAN, 2003). Além das fontes já citadas, redes sociais, wikis, e blogs também podem, e dependendo do foco de análise, devem ser consideradas como importantes fontes de informação textual devido principalmente a sua dinamicidade. Weiss (2005) afirma ainda que informações textuais em linguagem natural são importantes fontes de informação, e que na maioria das vezes são ignoradas pelas organizações. “Se por um lado essa situação propicia muitas oportunidades de uso dessa informação para a tomada de decisão, por outro, lança muitos desafios em como armazenar, recuperar e transformar essa informação em conhecimento” (BOVO, 2011).\nUm dos objetivos da análise da informação é a possibilidade de gerar conhecimento. Segundo Tuomi (1999) o caminho para o conhecimento é hierárquico, isto é, primeiramente são produzidos os dados (simples fatos) e em seguida, quando estruturados, são transformados em informação. A informação se torna conhecimento quando é interpretada, aplicada em um contexto, ou quando se adiciona significado à mesma. O conhecimento nos possibilita direcionar ações, tomar decisões, agir em determinadas situações (SCHREIBER et al., 2002). Autores como Wilson (2002) e Alavi et al. (2001) afirmam que o conhecimento envolve processos mentais, entendimento e aprendizagem, e como tal, reside somente na mente das pessoas. Afirmam ainda que tudo aquilo que se utiliza para expressar algo é realizado por meio de mensagens, desse modo, não constitui conhecimento e sim informação. Entretanto, outros autores consideram que o conhecimento pode ser explicitado (NONAKA; TAKEUCHI, 1995; SCHREIBER et al., 2002). Para Gonçalves (2006), não o conhecimento em si, mas redes de relacionamento, regras, padrões, tendências, entre outros, podem ser explicados e se constituem, portanto, em ativos de conhecimento. Esses ativos podem então, através de ferramental adequado, serem descobertos visando auxiliar em processos de tomada de decisão.\nEntre as possibilidades de ferramental visando identificar tais ativos a partir das informações geradas em determinado domínio encontram-se os processos de Descoberta de Conhecimento em Bases de Dados (Knowledge Discovery in Databases - KDD) e de Descoberta de Conhecimento em Texto (Knowledge Discovery in Texts - KDT).\nO processo de “KDD é o termo utilizado para promover a descoberta de conhecimento em bases de dados, e assim identificar e descrever os relacionamentos implícitos entre as informações nos bancos de dados em sistemas de uma organização” (SILVA; ROVER, 2011). Considerando o processo de KDT este é similar ao KDD, porém trabalha com um corpus (coleção de documentos) em linguagem natural, buscando padrões e tendências, classificando e comparando documentos (SILVA; ROVER, 2011). Apesar do objetivo em comum, a descoberta de conhecimento, o KDT e o KDD, possuem diferenças importantes. A principal delas refere-se ao tipo de informação uma vez que KDT trabalha com informações textuais (não estruturadas ou semi estruturadas), enquanto que o KDD trabalha com informações estruturadas, geralmente obtidas a partir de bancos de dados relacionais e/ou orientados a objetos.\nOs processos de descoberta de conhecimento são considerados não triviais, pois possuem diversas etapas compostas por algoritmos complexos, e trabalham com grande quantidade de informação, estruturada ou não. Esse fato se constitui em desafio uma vez que tais processos, quando executados a partir de uma infraestrutura computacional inadequada, podem inviabilizar a obtenção de resultados satisfatórios. Neste cenário, a computação distribuída desempenha um importante papel, e se torna uma solução viável no processamento de grande volume de informação. Segundo (TANENBAUM; STEEN, 2007) com a computação distribuída é possível utilizar um conjunto de computadores independentes, que na visão do usuário comportam-se como um sistema único e coerente. A principal motivação para a utilização de sistemas é a possibilidade de compartilhar recursos, tais como: componentes de hardware, discos, arquivos e bancos de dados (COULOURIS; DOLLIMORE; KINDBERG, 2005). Desse modo, a utilização da computação distribuída é uma solução plausível para tratar o crescente incremento no volume de informação, pois possibilita o desenvolvimento de sistemas capazes de analisar grandes fontes de informação com o objetivo de extrair ativos de conhecimento capazes de auxiliar no processo de tomada de decisão.",
    "Conclusão": "O objetivo geral desse trabalho foi desenvolver uma arquitetura que permita, de maneira distribuída, extrair ativos de conhecimento a partir de bases textuais. Nesse sentido, foi realizada uma revisão das áreas de descoberta de conhecimento e computação distribuída visando suportar a proposição do trabalho. Na base da arquitetura encontra-se o modelo de correlação rápida. Esse modelo procura simplificar a correlação tradicional uma vez que, ao invés de inspecionar todos os documentos para verificar a quantidade de determinado padrão (termo), considera-se somente a quantidade de documentos que mencionaram o termo. Tal abordagem possibilita ganho de desempenho quando aplicado de maneira distribuída. Salienta-se que em função dessa simplificação a precisão do processo de correlação é minimizada. Por outro lado, métodos tradicionais são custosos quando aplicados a grandes bases textuais. O método de correlação rápida que simplifica o processo de KDT e permite a análise temporal, característica baseada na proposta de Bovo (2011), se mostrou consistente e viabilizou a aplicação do modelo em grandes bases textuais. Com o intuito de melhorar o desempenho e oferecer possibilidades adicionais, o modelo foi implementado de modo que este possa ser executado de forma distribuída através do framework/middleware GridGain. O protótipo desenvolvido atendeu as expectativas gerando resultados satisfatórios e permitindo a produção de análises sobre determinado domínio de aplicação que podem ser expostas através de histogramas, gráficos, grafos, entre outros. A arquitetura distribuída do protótipo demonstrou flexibilidade e escalabilidade podendo ser expandida quando necessário por meio de computadores com hardware e sistemas operacionais distintos. Outro ponto importante a considerar refere-se ao modelo de dados que suporta o protótipo desenvolvido. Para tal, foi utilizado o conceito de modelagem dimensional em que tabelas são entendidas como dimensões (suporte) e fatos (registros que possuam alguma medida de valor). Esse modelo pode em princípio representar qualquer domínio de aplicação que se baseie em relacionamentos entre conceitos. Possui ainda, como característica importante, a possibilidade de representação de relacionamentos de maneira temporal. Ao longo deste trabalho surgiram novas possibilidades que não foram desenvolvidas, pois tornariam este trabalho muito extenso. As duas principais possibilidades são a implementação do modelo de associação entre elementos textuais e a adaptação do protótipo com o objetivo de utilizar semântica em seus processos. Apesar destes conceitos não terem sido acoplados ao protótipo, o modelo dimensional foi projetado pensando nessas futuras melhorias."
}